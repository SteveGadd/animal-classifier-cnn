{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMK2tGprsvtJFgOd88Hbsi6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SteveGadd/animal-classifier-cnn/blob/main/animal_classifier_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5vZaaVuSmdZP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor, Resize, Compose\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "torch.manual_seed(1864)\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"iamsouravbanerjee/animal-image-dataset-90-different-animals\")\n",
        "root_dir = os.path.expanduser(\"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\")\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),  # Resize to a fixed size\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = ImageFolder(root=root_dir, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total samples: {len(dataset)}\")\n",
        "\n",
        "# Classes\n",
        "print(f\"Number of classes: {len(dataset.classes)}\")\n",
        "\n",
        "# Sample shape\n",
        "img, label = dataset[0]\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Label index: {label}\")\n",
        "print(f\"Label name: {dataset.classes[label]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTtaQVUiP-KR",
        "outputId": "1f47436c-e832-4a39-df22-12c82bc07b9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 5400\n",
            "Number of classes: 90\n",
            "Image shape: torch.Size([3, 224, 224])\n",
            "Label index: 0\n",
            "Label name: antelope\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ImageClassifier Neural Network\n",
        "class ImageClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.model = nn.Sequential(\n",
        "      nn.Conv2d(3, 32, (3,3)),     # 222x222\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),             # 111x111\n",
        "      nn.Conv2d(32, 64, (3,3)),    # 109x109\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),             # 54x54\n",
        "      nn.Conv2d(64, 64, (3,3)),    # 52x52\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),             # 26x26\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(64*26*26, 90)\n",
        "  )\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n"
      ],
      "metadata": {
        "id": "jZ7QUQtyW2cD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ImageClassifier().to('cuda')\n",
        "opt = Adam(clf.parameters(),lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Privuxh5i0j4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        # Move data to GPU\n",
        "        X, y = X.to('cuda'), y.to('cuda')\n",
        "\n",
        "        # Forward pass\n",
        "        pred = clf(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        opt.zero_grad()  # Clear old gradients\n",
        "        loss.backward()  # Calculate gradients\n",
        "        opt.step()       # Update weights\n",
        "\n",
        "        # Print progress\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Batch {batch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND06wuAhpC9G",
        "outputId": "df81374d-903f-4c5e-a240-c61dc473f165"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Batch 0, Loss: 4.4956\n",
            "Epoch 0, Batch 100, Loss: 4.4854\n",
            "Epoch 1, Batch 0, Loss: 4.1881\n",
            "Epoch 1, Batch 100, Loss: 4.3880\n",
            "Epoch 2, Batch 0, Loss: 4.0688\n",
            "Epoch 2, Batch 100, Loss: 4.0768\n",
            "Epoch 3, Batch 0, Loss: 3.2647\n",
            "Epoch 3, Batch 100, Loss: 3.7306\n",
            "Epoch 4, Batch 0, Loss: 2.7674\n",
            "Epoch 4, Batch 100, Loss: 2.2553\n",
            "Epoch 5, Batch 0, Loss: 2.0205\n",
            "Epoch 5, Batch 100, Loss: 1.0718\n",
            "Epoch 6, Batch 0, Loss: 0.7111\n",
            "Epoch 6, Batch 100, Loss: 0.8207\n",
            "Epoch 7, Batch 0, Loss: 0.6395\n",
            "Epoch 7, Batch 100, Loss: 0.5218\n",
            "Epoch 8, Batch 0, Loss: 0.3857\n",
            "Epoch 8, Batch 100, Loss: 0.4351\n",
            "Epoch 9, Batch 0, Loss: 0.3677\n",
            "Epoch 9, Batch 100, Loss: 0.6102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick accuracy check\n",
        "correct = 0\n",
        "total = 0\n",
        "clf.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in val_loader:\n",
        "        X, y = X.to('cuda'), y.to('cuda')\n",
        "        pred = clf(X)\n",
        "        correct += (pred.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(f\"Accuracy: {100*correct/total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi3Y3mlDsa44",
        "outputId": "13f0ed05-4004-4a2c-9844-a12c103fb51e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.00%\n"
          ]
        }
      ]
    }
  ]
}